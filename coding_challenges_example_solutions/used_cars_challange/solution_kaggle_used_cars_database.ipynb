{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning coding challenge\n",
    "## \n",
    "Your task is to:\n",
    "1. Download the \"Used Cars Database\" from Kaggle Data Sets (https://www.kaggle.com/orgesleka/used-cars-database)\n",
    "1. Create whatever data subsets for training and testing you believe are appropriate.\n",
    "1. Build a predictive model, to predict which of the cars (listed at < 100k Euros) are listed as cheap (< 2,000 Euros), based on some combination of the other columns\n",
    "1. Produce results that convince us the estimate is a realistic measure of generalisation performance (if the model was to be deployed live for future listings).\n",
    "\n",
    "You may only use built-in Python 3 packages, and the basic scientific python kit such as numpy, sklearn, and pandas (no keras/tensorflow/spark please!).\n",
    "\n",
    "Also, everything must be done programmatically from this notebook, under the assumption \"autos.csv\" is placed in the same folder.\n",
    "\n",
    "## Part 2 - Resource Constraints\n",
    "To really impress it (and lets face it, that's what you're trying to do), now write code that follows this same process, but assuming the arbitrary resource limitation that you can only afford to load 1,000 rows of the data set into memory at once.\n",
    "\n",
    "\n",
    "## Priorities\n",
    "1. (40%) You use best practice machine learning process to get a *valid* result, and you comply with the resource limitations (i.e. your *code doesn't crash*).\n",
    "1. (30%) You adhere to general style and software engineering principles in writing your python code\n",
    "1. (10%) Your model performs reasonably well. I DON'T want you to waste time on extensive feature engineering to optimise model performance - just get a valid, better-than-random result.\n",
    "1. (10%) Your code runs reasonably efficiently, given the resource constraints (again, don't spend hours optimising...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "INSTALLATION AND SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Installed Kaggle to enable data download\n",
    "Downloaded and installed minconda\n",
    "Created conda environment called 'ipython' with ipython-notebook, numpy, pandas and scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install kaggle\n",
    "#bash Miniconda3-latest-MacOSX-x86_64.sh\n",
    "#conda create -n i_python ipython-notebook numpy pandas scikit-learn\n",
    "#conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Activate the i_python environment, change to the chosen working directory and start the codeing_test2.ipynb notebook.\n",
    "Downloaded and installed minconda\n",
    "Created conda environment called 'ipython' with ipython-notebook, numpy, pandas and scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source activate i_python\n",
    "#ipython notebook coding_test_2_solution_BroichM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Clear variables and libs, then load the required packages and print their versions.\n",
    "The versions used in this solution where:\n",
    "Python version 3.5.5\n",
    "numpy version 1.14.2.\n",
    "pandas version  0.22.0.\n",
    "scikit-learn version  0.19.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.5.5\n",
      "The numpy version is 1.14.2.\n",
      "The pandas version is 0.22.0.\n",
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "# clear all variables and libs\n",
    "def clearall():\n",
    "    all = [var for var in globals() if \"__\" not in (var[:2], var[-2:])]\n",
    "    for var in all:\n",
    "        del globals()[var]\n",
    "clearall()\n",
    "\n",
    "#import libs\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"The Python version is %s.%s.%s\" % sys.version_info[:3])\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "print('The pandas version is {}.'.format(pd.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " Download the data, move to working dir and unzip (working dir on my mac is: /Users/mb/Desktop/near_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'_oh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2afaaef0ad43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unzip used-cars-database.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/i_python/lib/python3.5/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/i_python/lib/python3.5/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mupdate_user_ns\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Avoid recursive reference when displaying _oh/Out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_oh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_oh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_full_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcull_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '_oh'"
     ]
    }
   ],
   "source": [
    "com = \"kaggle datasets download -d orgesleka/used-cars-database\"\n",
    "os.system(com)\n",
    "com = \"mv ../../.kaggle/datasets/orgesleka/used-cars-database/used-cars-database.zip .\"\n",
    "os.system(com)\n",
    "com = \"unzip used-cars-database.zip\"\n",
    "os.system(com) #produces an error but does the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Define the functions (including random forest used in this solution)\n",
    "In response to the specs the preprocessing function marks 50% of the cars as training data and the remaining 50% as cases that we will predict/ test the model on. The precition/ testing data is not used in the model (e.g. cross validation) but set aside. Using 50% is conservative and the resutling accuracy can be assumed to generlaize well to a new set of cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def func_preprocess(df):\n",
    "    \"\"\"\n",
    "    v 1.0 To preprocess the dataframe including the selection of fitting and testing data\n",
    "    :param dataframe:\n",
    "    :return: preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    #drop columns with liklely minor importance for prediction\n",
    "    df.drop(['dateCrawled','name', 'seller', 'offerType', 'abtest','gearbox','model','monthOfRegistration','fuelType','notRepairedDamage','dateCreated', 'nrOfPictures', 'postalCode','lastSeen'], axis='columns', inplace=True)\n",
    "    \n",
    "    #add another colume with random 0 or 1 to the df to use as train and test dataset (here spitting 50/50)\n",
    "    slength = df.shape[0]\n",
    "    # flag 1 is used for fitting so setting p=[0.75, 0.25] would result in a 25% fitting sample\n",
    "    df['fit_eval'] = np.random.choice([0, 1],slength, p=[0.5, 0.5])\n",
    "\n",
    "    #find all NaN and repalce with mode value for all column in df\n",
    "    for column in df.columns:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "\n",
    "    #translate the categy variables into integer\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == type(object):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit_transform(df[column])\n",
    "            df[column] = le.fit_transform(df[column])            \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# run func_preprocess v 1.0 \n",
    "#df = func_preprocess(df)\n",
    "\n",
    "def func_business(df):\n",
    "    \"\"\"\n",
    "    v 1.0 To apply the business rules\n",
    "    :param dataframe:\n",
    "    :return: preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    #subset cars listed at < 100k Euros as per specs\n",
    "    df[df.price < 100000]\n",
    "\n",
    "    #which of the cars (listed at < 100k Euros) are listed as cheap (< 2,000 Euros) as per specs, \n",
    "    #code the y variable as 1 and 0 for price <2000 and >= 2000 euro, respectivley \n",
    "    df['y'] = np.where(df['price']<2000, 1, 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# run func_business v 1.0 \n",
    "#df = func_business(df)\n",
    "\n",
    "\n",
    "def func_select_fit_eval(df,fit):\n",
    "    \"\"\"\n",
    "    v 1.0 To select fitting and evaluation dataset for training \n",
    "        or application of model  \n",
    "    :param df:\n",
    "    :param fit flag:\n",
    "    :return: train_test_x, train_test_y\n",
    "    \"\"\"\n",
    "    \n",
    "    #subset the x variables and the y variable\n",
    "    #the last two variables are y and the identifyier of train and test dataset\n",
    "    #these are not included in the x variables\n",
    "    x_header = df.columns[1:len(df.columns)-2]\n",
    "    y_header = df.columns[-1] ### last one?\n",
    "    \n",
    "    #the function can be called to provide input for train or test dataset\n",
    "    if(fit == 1):     \n",
    "        # pick only the fitting data\n",
    "        df_fit = df[df['fit_eval'] == 0]\n",
    "        train_test_x = df_fit[x_header]\n",
    "        train_test_y = df_fit[y_header]\n",
    "    else:\n",
    "        # pick only the data not used for fitting\n",
    "        df_eval = df[df['fit_eval'] == 1]\n",
    "        train_test_x = df_eval[x_header]\n",
    "        train_test_y = df_eval[y_header]\n",
    "        \n",
    "    return train_test_x, train_test_y\n",
    "\n",
    "# run select v 1.0 \n",
    "#fit = 1 #or fit = 2\n",
    "#train_test_xy = func_create_fit_eval(df,fit)\n",
    "#train_test_x = train_test_xy[0]\n",
    "#train_test_y = train_test_xy[1]\n",
    "\n",
    "\n",
    "def func_random_forest(clf, treecount,counter):\n",
    "#def func_random_forest(treecount,counter):\n",
    "    \"\"\"\n",
    "    v 1.0 To fit random forest\n",
    "    :param random forest obejcts:\n",
    "    :param tree counter:\n",
    "    :param counter:\n",
    "    :return: random forest obejcts\n",
    "    \"\"\"\n",
    "    \n",
    "    if(counter ==0):\n",
    "        # for first chunk create random forest model using all remaining features \n",
    "        # set warm_start=True so that more trees can be added for subsequent chunks\n",
    "        clf = RandomForestClassifier(n_estimators = treecount,warm_start=True, max_features = 5, n_jobs = 1)\n",
    "        clf.fit(train_test_x, train_test_y)        \n",
    "    else:\n",
    "        # add more trees for subsequent chunks\n",
    "        clf.set_params(n_estimators = treecount)\n",
    "        clf.fit(train_test_x, train_test_y)    \n",
    "    \n",
    "    return clf\n",
    "\n",
    "# run func_random forest v 1.0 \n",
    "#clf = func_random_forest(clf,treecount,counter)\n",
    "\n",
    "\n",
    "def func_accuracy(ys,predictions):\n",
    "    \"\"\"\n",
    "    v 1.0 To calculate accuraies and f1 score \n",
    "    :param ys:\n",
    "    :param predictions:\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    \n",
    "    ## flattern the prediction results and the y variable harverested from the chunks; \n",
    "    counter = 0\n",
    "    global y \n",
    "    global y_hat_model  \n",
    "    for name, prediction in predictions:\n",
    "        y.extend(ys[counter][1])\n",
    "        y_hat_model.extend(predictions[counter][1])\n",
    "        counter = counter + 1\n",
    "\n",
    "    y = np.asarray(y)\n",
    "    y_hat_model = np.asarray(y_hat_model)\n",
    "    \n",
    "\n",
    "    #count the confusion matrix values\n",
    "    #result count \n",
    "    all_count = len(y)\n",
    "    #count of cars < 2k\n",
    "    all_pos = sum(y)\n",
    "    #count of cars predicted as < 2k\n",
    "    all_hat = sum(y_hat_model)\n",
    "    \n",
    "    #corred cars < 2k\n",
    "    correct_pos = sum((y==1) & (y_hat_model==1))\n",
    "    #corred cars >= 2k\n",
    "    correct_neg = sum((y==0) & (y_hat_model==0))\n",
    "\n",
    "    #p (precision) is correct positive results divided by all positive results returned by the classifier. \n",
    "    p = correct_pos / all_hat\n",
    "    #r (recall) is correct positive results divided by all samples that should have been identified as positive. \n",
    "    r = correct_pos / all_pos\n",
    "    #f1 score is the harmonic average of the precision and recall,\n",
    "    f1 = 2 * (p * r / (p + r))\n",
    "    #overall accuracy\n",
    "    o = (correct_pos + correct_neg) /all_count\n",
    "\n",
    "    #print overall accurcy, recall, precision, and f1 score w 5 d.p.\n",
    "    print('overall_accuracy',round(o,3), 'recall',round(r,3), 'precision',round(p,3), 'f1',round(f1,3))\n",
    "\n",
    "# run func_accuracy v 1.0 \n",
    "#run func_accuracy(ys,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Set lists and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = []\n",
    "clf = []\n",
    "predictions = []\n",
    "ys = []\n",
    "y = []\n",
    "y_hat_model = []\n",
    "\n",
    "# do one random forest tree per chunk and use a chunk size of 1000 as per specs\n",
    "treecount = 1\n",
    "chunksize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start timer\n",
    "start = time.time()\n",
    "\n",
    "#fit the model by building up a random forest adding one tree per chunk of lines read\n",
    "#the result of 'clf' contraining a random forest with as many tree as number of chunks times treecount \n",
    "#(which is set by the user) \n",
    "#this loop also produces 'evals' a vector denoting which cars have been used for fitting\n",
    "\n",
    "counter = 0\n",
    "for df in pd.read_csv(\"autos.csv\", chunksize=chunksize ,encoding='latin-1'):\n",
    "\n",
    "    # run func_preprocess v 1.0 \n",
    "    df = func_preprocess(df)\n",
    "\n",
    "    #capture the fit_evals\n",
    "    evals.append((counter, df['fit_eval']))\n",
    "\n",
    "    # run func_business v 1.0 \n",
    "    df = func_business(df)\n",
    "    #print(list(df))\n",
    "\n",
    "    ## func to select fitting or application data\n",
    "    # here fitting\n",
    "    fit = 1\n",
    "    train_test_xy = func_select_fit_eval(df,fit)\n",
    "    train_test_x = train_test_xy[0]\n",
    "    train_test_y = train_test_xy[1]\n",
    "\n",
    "    # run func_random_forest v 1.0 \n",
    "    clf = func_random_forest(clf,treecount,counter)\n",
    "\n",
    "    counter = counter + 1\n",
    "    treecount = treecount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the 'clf' model to one chunk at a time\n",
    "# the loop laos reads back the 'evals' a vector denoting which cars have been used for fitting\n",
    "# so that only once not used for fitting are used for prediction and later evalaution\n",
    "\n",
    "#this loop results in two vecotrs: 'predictions' and 'ys' that denote the model results and the \n",
    "#true results respectivley\n",
    "\n",
    "counter = 0\n",
    "for df in pd.read_csv(\"autos.csv\", chunksize=chunksize ,encoding='latin-1'):\n",
    "    # run func_preprocess v 1.0 \n",
    "    df = func_preprocess(df) \n",
    "\n",
    "    # run func_business v 1.0 \n",
    "    df = func_business(df)\n",
    "\n",
    "    #### read fit_eval back into the df\n",
    "    eval = evals[counter][1]\n",
    "    df['fit_eval'] = eval\n",
    "\n",
    "    # func to select fitting or application data\n",
    "    # here application\n",
    "    fit = 0\n",
    "    train_test_xy = func_select_fit_eval(df,fit)\n",
    "    train_test_x = train_test_xy[0]\n",
    "    train_test_y = train_test_xy[1]\n",
    "\n",
    "    ## predict and append the predictions and the ys\n",
    "    predictions.append((counter, clf.predict(train_test_x)))\n",
    "    ys.append((counter, train_test_y))\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.825 precision 0.822 overall accuracy 0.86 f1 0.824\n",
      "runtime in min: 0.7175386508305868\n"
     ]
    }
   ],
   "source": [
    "# run func_accuracy v 1.0 \n",
    "func_accuracy(ys,predictions)\n",
    "\n",
    "#end timer\n",
    "end = time.time()\n",
    "print(\"runtime in min:\",(end - start)/60)# time in min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in less then 1 min of runtime I got >80% accuracy as compared to 50%, which would be the random benchmark as per specs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
